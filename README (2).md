
# Classification Models Comparison

This project demonstrates the implementation and visualization of different machine learning classification models, including:

- **Random Forest Classifier**
- **Kernel SVM**
- **K-Nearest Neighbors (K-NN)**
- **Decision Tree Classifier**

## Project Overview

The notebooks included in this repository show how to train, test, and visualize these classifiers on a dataset. 
Each notebook corresponds to a different classification algorithm and provides insights into the model's decision boundaries.

## Models Implemented

1. **Random Forest Classifier**
   - Uses an ensemble of decision trees to improve classification accuracy.
2. **Kernel SVM**
   - A Support Vector Machine with kernel trick for non-linear classification.
3. **K-NN (K-Nearest Neighbors)**
   - A distance-based algorithm that classifies data points based on their neighbors.
4. **Decision Tree Classifier**
   - A tree-structured model for classification.

## Result on Test Set

The following figure shows the decision boundaries of all four models on the test set:

![Result on Test Set](Untitled%20design.png)

## Files Included

- `random_forest_classifier.ipynb` - Implementation of Random Forest Classifier.
- `kernel_svm.ipynb` - Implementation of Kernel SVM.
- `knn.ipynb` - Implementation of K-Nearest Neighbors.
- `decision_tree_classifier.ipynb` - Implementation of Decision Tree Classifier.
- `Untitled design.png` - Visualization of the results on the test set.

## How to Run

1. Clone this repository.
2. Open any of the Jupyter notebooks in your environment.
3. Run the cells to train and visualize the classifiers.

